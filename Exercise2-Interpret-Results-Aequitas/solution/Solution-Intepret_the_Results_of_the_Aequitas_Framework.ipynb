{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8083e30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we will ensure that we can successfully import the aequitas framework\n",
    "\n",
    "import aequitas\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# next, we will design a dataframe that is suitable for the aequitas framework. \n",
    "# Input data must have at least one sensitive variable (race, age, sex, income)\n",
    "# The label value must be binary and the score value can be binary or continuous\n",
    "\n",
    "'''\n",
    "Below, you will find a link to the COMPAS dataset that describes rates of crime recidivism among\n",
    "different demographic groups. Import the dataset and run the graph below to display the rates\n",
    "of crime recidivism among different ethnic groups.\n",
    "'''\n",
    "\n",
    "aequitas_df = pd.read_csv(\"../data/compas_for_aequitas.csv\")\n",
    "\n",
    "# print the output of your aequitas_df\n",
    "\n",
    "by_race = sns.countplot(x=\"race\", hue=\"score\", data=aequitas_df[aequitas_df.race.isin(['African-American', 'Caucasian', 'Hispanic'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea845d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "In this exercise, we will use Aequitas to compute the crosstabular metrics\n",
    "which can be used to subsequently calculate disparity metrics between groups below.\n",
    "'''\n",
    "\n",
    "from aequitas import Audit\n",
    "from aequitas.bias import Bias\n",
    "from aequitas.fairness import Fairness\n",
    "from aequitas.plotting import Plot\n",
    "from aequitas.group import Group\n",
    "\n",
    "# first, import the Group() function\n",
    "# Next, calculate the crosstabs for your dataset and print them out below\n",
    "\n",
    "g = Group()\n",
    "xtab, _ = g.get_crosstabs(aequitas_df)\n",
    "\n",
    "\n",
    "\n",
    "#bdf = b.get_disparity_predefined_groups(xtab, original_df=df, ref_groups_dict={'race':'Caucasian', 'sex':'Male', 'age_cat':'25 - 45'}, alpha=0.05, mask_significance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c4942e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Disparities Calculated:\n",
    "\n",
    "True Positive Rate Disparity - ‘tpr_disprity’\n",
    "\n",
    "True Negative Rate - ‘tnr_disparity’\n",
    "\n",
    "False Omission Rate - ‘for_disparity’\n",
    "\n",
    "False Discovery Rate - ‘fdr_disparity’\n",
    "\n",
    "False Positive Rate - ‘fpr_disparity’\n",
    "\n",
    "False NegativeRate - ‘fnr_disparity’\n",
    "\n",
    "Negative Predictive Value - ‘npv_disparity’\n",
    "\n",
    "Precision Disparity - ‘precision_disparity’\n",
    "\n",
    "Predicted Positive Ratio_k Disparity - ‘ppr_disparity’\n",
    "\n",
    "Predicted Positive Ratio_g Disparity - ‘pprev_disparity’\n",
    "'''\n",
    "\n",
    "# Next, import the Bias() function and set it to a variable\n",
    "\n",
    "b = Bias()\n",
    "\n",
    "# Now, use the get_disparity_predefined_groups function to set a reference group and calculate disparity relative to that reference group\n",
    "\n",
    "hbdf = b.get_disparity_predefined_groups(xtab, original_df=aequitas_df,\n",
    "                                         ref_groups_dict={'race':'Caucasian', 'sex':'Male', 'age_cat':'25 - 45'},\n",
    "                                         alpha=0.05,\n",
    "                                         mask_significance=False)\n",
    "\n",
    "# Finally, print out the disparity calculations for visualization below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3838c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hbdf[['attribute_name','attribute_value','fpr_disparity','fnr_disparity']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd82108",
   "metadata": {},
   "source": [
    "<b>In the space below, describe what the False Positive Ratio and the False Negative Rate tell you about the disparities between the groups:</b>\n",
    "\n",
    "<i>The model we have trained has proclivity to suspect African Americans, Native Americans, and people under the age of 25 as shown with it's higher rate of 'fpr_disparity'. Hispanics receive a boost with a slightly higher false negative rate and people over the age of 45 see a significantly higher false negative rate. Hence, they are less likely to be predicted as repeat offenders by the model.\n",
    "\n",
    "The goal in the future should be to reduce the bias in both of these areas.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fc4c5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
